{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"datasets/kitti/depth_selection/val_selection_cropped/\"\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    ! mkdir -p datasets/kitti\n",
    "    ! wget -O datasets/kitti.zip https://s3.eu-central-1.amazonaws.com/avg-kitti/data_depth_selection.zip\n",
    "    ! unzip -q -o datasets/kitti.zip -d datasets/kitti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "num_samples = 600\n",
    "\n",
    "for image_path in tqdm(glob.glob(path + \"image/\" + \"*.png\"), desc=\"Loading Images\"):\n",
    "    x = Image.open(image_path)\n",
    "    x = x.convert('RGB')\n",
    "    \n",
    "    width = math.floor(x.size[0] * 256 / x.size[1])\n",
    "    x_offset = random.randint(0, width - 256)\n",
    "    \n",
    "    x = x.resize((width, 256))\n",
    "    x = x.crop((x_offset, 0, x_offset + 256, 256))\n",
    "    xs.append(np.array(x.getdata()).reshape((256, 256, 3)) / 255)\n",
    "\n",
    "    y = Image.open(image_path.replace('/image/', '/groundtruth_depth/').replace('sync_image', 'sync_groundtruth_depth'))\n",
    "    y = y.convert('L')\n",
    "    y = y.resize((width, 256))\n",
    "    y = y.crop((x_offset, 0, x_offset + 256, 256))\n",
    "    y = np.array(y.getdata()).reshape((256, 256, 1)) / 255\n",
    "    ys.append(y)\n",
    "    \n",
    "    if len(xs) >= num_samples:\n",
    "        break;\n",
    "\n",
    "xs = np.array(xs)\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of random images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(6,6,figsize=(16,16))\n",
    "fig.tight_layout()\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(18):\n",
    "    rand = np.random.randint(len(xs)-1)\n",
    "    x = xs[rand]\n",
    "    y = ys[rand].reshape((256, 256))\n",
    "    \n",
    "    ax[2 * i].imshow(x)\n",
    "    ax[2 * i].set_title(f\"{i}_x\")\n",
    "    ax[2 * i].axis(\"off\")\n",
    "    ax[2 * i + 1].imshow(y)\n",
    "    ax[2 * i + 1].set_title(f\"{i}_y\")\n",
    "    ax[2 * i + 1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import pix2pix and generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pix2pix.ipynb\n",
    "\n",
    "model = Pix2pix(output_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_x, train_y), (test_x, test_y)) = model.split_dataset(xs, ys, validation_split=0.05)\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=10, epochs=150, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize results of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_x, batch_size=10)\n",
    "for i in range(len(out)):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(10,10))\n",
    "    fig.tight_layout()\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    x = test_x[i]\n",
    "    y = test_y[i].reshape((256, 256))\n",
    "    o = out[i].reshape((256, 256))\n",
    "    \n",
    "    ax[0].imshow(x)\n",
    "    ax[0].set_title(\"x\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(y)\n",
    "    ax[1].set_title(\"y\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].imshow(o)\n",
    "    ax[2].set_title(\"g(x)\")\n",
    "    ax[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
