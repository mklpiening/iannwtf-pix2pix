{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"datasets/outdoor/\"\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    ! mkdir -p datasets/outdoor\n",
    "    ! wget -O datasets/outdoor.tar http://transattr.cs.brown.edu/files/aligned_images.tar\n",
    "    ! tar -C datasets/outdoor -xf datasets/outdoor.tar\n",
    "    ! wget -O datasets/outdoor1.tar http://transattr.cs.brown.edu/files/annotations.tar\n",
    "    ! tar -C datasets/outdoor -xf datasets/outdoor1.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset\n",
    "available annotations:\n",
    "- 0: **dirty**\n",
    "- 1: **daylight**\n",
    "- 2: **night**\n",
    "- 3: **sunrisesunset**\n",
    "- 4: **dawndusk**\n",
    "- 5: **sunny**\n",
    "- 6: **clouds**\n",
    "- 7: **fog**\n",
    "- 8: **storm**\n",
    "- 9: **snow**\n",
    "- 10: **warm**\n",
    "- 11: **cold**\n",
    "- 12: **busy**\n",
    "- 13: **beautiful**\n",
    "- 14: **flowers**\n",
    "- 15: **spring**\n",
    "- 16: **summer**\n",
    "- 17: **autumn**\n",
    "- 18: **winter**\n",
    "- 19: **glowing**\n",
    "- 20: **colorful**\n",
    "- 21: **dull**\n",
    "- 22: **rugged**\n",
    "- 23: **midday**\n",
    "- 24: **dark**\n",
    "- 25: **bright**\n",
    "- 26: **dry**\n",
    "- 27: **moist**\n",
    "- 28: **windy**\n",
    "- 29: **rain**\n",
    "- 30: **ice**\n",
    "- 31: **cluttered**\n",
    "- 32: **soothing**\n",
    "- 33: **stressful**\n",
    "- 34: **exciting**\n",
    "- 35: **sentimental**\n",
    "- 36: **mysterious**\n",
    "- 37: **boring**\n",
    "- 38: **gloomy**\n",
    "- 39: **lush**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_x = 18\n",
    "attribute_y = 16\n",
    "\n",
    "files = []\n",
    "\n",
    "with open(path + 'annotations/annotations.tsv', newline='') as annotations:\n",
    "    annotations = csv.reader(annotations, delimiter='\\t')\n",
    "    \n",
    "    current_img_path = \"\"\n",
    "    current_img_attributes = {}\n",
    "    for row in annotations:\n",
    "        scene = row[0].split('/')[0]\n",
    "        if scene != current_img_path:\n",
    "            if attribute_x in current_img_attributes and attribute_y in current_img_attributes:\n",
    "                for file_x in current_img_attributes[attribute_x]:\n",
    "                    for file_y in current_img_attributes[attribute_y]:\n",
    "                        files.append((current_img_path + '/' + file_x, current_img_path + '/' + file_y))\n",
    "            \n",
    "            current_img_path = scene\n",
    "            current_img_attributes = {}\n",
    "            \n",
    "        for i in range(1, len(row)):\n",
    "            if float(row[i].split(',')[0]) > 0.8:\n",
    "                if i - 1 in current_img_attributes:\n",
    "                    current_img_attributes[i - 1].append(row[0].split('/')[1])\n",
    "                else:\n",
    "                    current_img_attributes[i - 1] = [row[0].split('/')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce loading time by reducing amount of samples\n",
    "num_samples = 800\n",
    "\n",
    "random.shuffle(files)\n",
    "files = files[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for (file_x, file_y) in tqdm(files):\n",
    "    x = Image.open(path + \"imageAlignedLD/\" + file_x)\n",
    "    x = x.convert('RGB')\n",
    "    x = x.resize((256, 256))\n",
    "\n",
    "    y = Image.open(path + \"imageAlignedLD/\" + file_y)\n",
    "    y = y.convert('RGB')\n",
    "    y = y.resize((256, 256))\n",
    "    \n",
    "    xs.append(np.array(x.getdata()).reshape((256, 256, 3)) / 255)\n",
    "    ys.append(np.array(y.getdata()).reshape((256, 256, 3)) / 255)\n",
    "\n",
    "xs = np.array(xs)\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of random images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(6,6,figsize=(16,16))\n",
    "fig.tight_layout()\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(18):\n",
    "    rand = np.random.randint(len(xs)-1)\n",
    "    x = xs[rand]\n",
    "    y = ys[rand]\n",
    "    \n",
    "    ax[2 * i].imshow(x)\n",
    "    ax[2 * i].set_title(f\"{i}_x\")\n",
    "    ax[2 * i].axis(\"off\")\n",
    "    ax[2 * i + 1].imshow(y)\n",
    "    ax[2 * i + 1].set_title(f\"{i}_y\")\n",
    "    ax[2 * i + 1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import pix2pix and generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pix2pix.ipynb\n",
    "\n",
    "model = Pix2pix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_x, train_y), (test_x, test_y)) = model.split_dataset(xs, ys, validation_split=0.05)\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=10, epochs=150, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize results of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_x, batch_size=10)\n",
    "for i in range(len(out)):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(10,10))\n",
    "    fig.tight_layout()\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    x = test_x[i]\n",
    "    y = test_y[i]\n",
    "    o = out[i]\n",
    "    \n",
    "    ax[0].imshow(x)\n",
    "    ax[0].set_title(\"x\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(y)\n",
    "    ax[1].set_title(\"y\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].imshow(o)\n",
    "    ax[2].set_title(\"g(x)\")\n",
    "    ax[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
