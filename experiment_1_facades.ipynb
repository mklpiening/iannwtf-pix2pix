{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pix facades\n",
    "This example uses the pix2pix notebook which implements the pix2pix conditional GAN to convert images of facades from densel labels of the facade elements.\n",
    "\n",
    "This example is also used in the pix2pix paper and is included to show general functionality of our implementaion of the pix2pix architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "Before training the network we need to download and prepare our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download dataset\n",
    "To get the dataset we download is directly from the official [website of the dataset](http://cmp.felk.cvut.cz/~tylecr1/facade/) if it has not been downloaded yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"datasets/facades/base/\"\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    ! mkdir -p datasets/facades\n",
    "    ! wget -O datasets/facades.zip http://cmp.felk.cvut.cz/~tylecr1/facade/CMP_facade_DB_base.zip\n",
    "    ! unzip -q -o datasets/facades.zip -d datasets/facades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset\n",
    "After downloading the dataset, we prepare it. Because it contains per entry one png for the labels and one jpg for the image, we simply replace the .png with a .jpg to get the image for one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_jitter(x, y):\n",
    "    x_out = x.resize((286, 286))\n",
    "    y_out = y.resize((286, 286))\n",
    "    \n",
    "    x_start = random.randint(0, 30)\n",
    "    y_start = random.randint(0, 30)\n",
    "    \n",
    "    x_out = x_out.crop((x_start, y_start, x_start + 256, y_start + 256))\n",
    "    y_out = y_out.crop((x_start, y_start, x_start + 256, y_start + 256))\n",
    "    \n",
    "    if random.randint(0, 1) > 0:\n",
    "        x_out = x_out.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        y_out = y_out.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "    return (x_out, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for image_path in tqdm_notebook(glob.glob(path + \"*.png\")):\n",
    "    # load the labels of the current entry\n",
    "    x = Image.open(image_path)\n",
    "    x = x.convert('RGB')\n",
    "\n",
    "    # load the image of the current entry\n",
    "    y = Image.open(image_path.replace(\".png\", \".jpg\"))\n",
    "    y = y.convert('RGB')\n",
    "    \n",
    "    # apply random jitter\n",
    "    for i in range(random.randint(0, 4)):\n",
    "        x_out, y_out = random_jitter(x, y)\n",
    "        xs.append(np.array(x_out.getdata()).reshape((256, 256, 3)) / 255)\n",
    "        ys.append(np.array(y_out.getdata()).reshape((256, 256, 3)) / 255)\n",
    "\n",
    "xs = np.array(xs)\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of random images and their labels\n",
    "After loading the images and labels we visualize some pairs of our dataset to see if all went correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(6,6,figsize=(16,16))\n",
    "fig.tight_layout()\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(18):\n",
    "    rand = np.random.randint(len(xs)-1)\n",
    "    x = xs[rand]\n",
    "    y = ys[rand]\n",
    "    \n",
    "    ax[2 * i].imshow(x)\n",
    "    ax[2 * i].set_title(f\"{i}_x\")\n",
    "    ax[2 * i].axis(\"off\")\n",
    "    ax[2 * i + 1].imshow(y)\n",
    "    ax[2 * i + 1].set_title(f\"{i}_y\")\n",
    "    ax[2 * i + 1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {\"logs/facades/\"} --host 0.0.0.0 --port 8008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pix2pix and generate model\n",
    "After creating our dataset we load and create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pix2pix.ipynb\n",
    "\n",
    "model = Pix2pix(discriminator=Discriminator286())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow a consistent split between training and test dataset we split our dataset before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((train_x, train_y), (test_x, test_y)) = model.split_dataset(xs, ys, validation_split=0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint stuff\n",
    "To pause the training process and resume it later we use automatic checkpoints.\n",
    "Before setting up these automatic checkpoints we check if a earlier checkpoint exists and if so load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/facades/'\n",
    "checkpoint_path = checkpoint_dir + 'checkpoint-{epoch:04d}.ckpt'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# if a checkpoint exists => build model and load weights\n",
    "if tf.train.latest_checkpoint(checkpoint_dir) != None:\n",
    "    model.build(train_x.shape)\n",
    "    status = model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit model\n",
    "Now, after loading the model and potentially restoring it from a earlier checkpoint, we create our needed callbacks and train the model.\n",
    "\n",
    "To show TQDM progress bars in Jupyter Lab run install the jupyterlab-manager widget before training:\n",
    "``` bash\n",
    "$ jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback for progressbars\n",
    "tqdm_callback = TQDMNotebookCallback(inner_description_update=\"Epoch: {epoch}\")\n",
    "\n",
    "# callback for automatic checkpoints\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False)\n",
    "\n",
    "# callback for tensorboard\n",
    "tensorboard_calback = tf.keras.callbacks.TensorBoard(log_dir='logs/facades/', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch')\n",
    "\n",
    "# train the model\n",
    "model.fit(train_x, train_y, batch_size=10, epochs=50, initial_epoch=0, validation_data=(test_x, test_y), callbacks=[tqdm_callback, checkpoint_callback, tensorboard_calback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize results of test data\n",
    "After training the model, we visualize some examples from our tesing dataset including the input, output and expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(test_x, batch_size=10)\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(10,10))\n",
    "    fig.tight_layout()\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    x = test_x[i]\n",
    "    y = test_y[i]\n",
    "    o = out[i]\n",
    "    \n",
    "    ax[0].imshow(x)\n",
    "    ax[0].set_title(\"x\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(y)\n",
    "    ax[1].set_title(\"y\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].imshow(o)\n",
    "    ax[2].set_title(\"g(x)\")\n",
    "    ax[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize results of training data\n",
    "Now we also visualize our results on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(train_x[:10], batch_size=10)\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(10,10))\n",
    "    fig.tight_layout()\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    x = train_x[i]\n",
    "    y = train_y[i]\n",
    "    o = out[i]\n",
    "    \n",
    "    ax[0].imshow(x)\n",
    "    ax[0].set_title(\"x\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].imshow(y)\n",
    "    ax[1].set_title(\"y\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[2].imshow(o)\n",
    "    ax[2].set_title(\"g(x)\")\n",
    "    ax[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
